{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling I: direct and importance sampling\n",
    "\n",
    "\n",
    "## Content\n",
    "- Monte Carlo integration methods\n",
    "\n",
    "## Remember jupyter notebooks\n",
    "- To run the currently highlighted cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>.\n",
    "- To get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Area under a curve\" via direct Monte Carlo sampling\n",
    "\n",
    "Let us define `f1(x, mu, sigma)` which evaluates\n",
    "\n",
    "$$f1(x, \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left( -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right)$$\n",
    "\n",
    "as well as `f2(x)` and  `f3(x)` which evaluate superpositions of `f1` calls for different centers and scales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, mu=0.0, sigma=1.0):\n",
    "    gauss_curve = np.exp(-(x - mu)**2 / (2.0 * sigma**2))\n",
    "    area = np.sqrt(2.0 * np.pi) * sigma\n",
    "    return gauss_curve / area\n",
    "\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, f1(x))\n",
    "ax.fill_between(x, 0, f1(x), alpha=0.3)\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$f1(x)$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_mc(func, xmin, xmax, size):\n",
    "    x = np.random.uniform(low=xmin, high=xmax, size=size)\n",
    "    f = func(x)\n",
    "    ymax = f.max()\n",
    "    x_width = xmax - xmin\n",
    "    y = np.random.uniform(low=0, high=ymax, size=size)\n",
    "    n = np.sum(y < f)\n",
    "    area = x_width * ymax\n",
    "    ratio = n / size\n",
    "    return area * ratio, area, ratio\n",
    "\n",
    "\n",
    "integrate_mc(f1, -5, 5, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x):\n",
    "    return 0.5 * (f1(x, mu=-2, sigma=0.5) + f1(x, mu=2, sigma=0.5))\n",
    "\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, f2(x))\n",
    "ax.fill_between(x, 0, f2(x), alpha=0.3)\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$f2(x)$')\n",
    "fig.tight_layout()\n",
    "\n",
    "integrate_mc(f2, -5, 5, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(x):\n",
    "    return 0.5 * (f1(x, mu=-4.5, sigma=0.05) + f1(x, mu=4.5, sigma=0.05))\n",
    "\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, f3(x))\n",
    "ax.fill_between(x, 0, f3(x), alpha=0.3)\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$f3(x)$')\n",
    "fig.tight_layout()\n",
    "\n",
    "integrate_mc(f3, -5, 5, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "How do the standard deviations of the integrals of the three functions scale with the number of evaluation points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for i, f in enumerate((f1, f2, f3)):\n",
    "    data = None\n",
    "    ax.plot(n_values, data, '-o', linewidth=2, color=f'C{i}', label=f'f{i + 1}')\n",
    "    ax.fill_between(n_values, 0, data, facecolor=f'C{i}', alpha=0.3)\n",
    "\n",
    "ax.semilogx()\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'$N$')\n",
    "ax.set_ylabel(r'$\\sigma$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does `f3` scale so much worde than the two other functions? We can understand this problem by looking at the ratios of the areas under the curves versus the total integration/sampling areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_mc_show(func, xmin, xmax, size, ax=None):\n",
    "    x = np.random.uniform(low=xmin, high=xmax, size=size)\n",
    "    f = func(x)\n",
    "    ymax = f.max()\n",
    "    x_width = xmax - xmin\n",
    "    y = np.random.uniform(low=0, high=ymax, size=size)\n",
    "    n = np.sum(y < f)\n",
    "    area = x_width * ymax\n",
    "    ratio = n / size\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    ax.plot([xmin] * 2, [0, ymax], color='C3')\n",
    "    ax.plot([xmax] * 2, [0, ymax], color='C3')\n",
    "    ax.plot([xmin, xmax], [0] * 2, color='C3')\n",
    "    ax.plot([xmin, xmax], [ymax] * 2, color='C3')\n",
    "    ax.scatter(x, y, c=y < f, s=0.1)\n",
    "    ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(r'$y$')\n",
    "    return area * ratio, area, ratio, ax\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "for i, (ax, f) in enumerate(zip(axes.flat, (f1, f2, f3))):\n",
    "    _, _, ratio, _ = integrate_mc_show(f, -5, 5, 10000, ax=ax)\n",
    "    ax.set_title(f'f{i + 1}, {ratio}')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing expectation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_potential(x):\n",
    "    return np.power(x, 2)\n",
    "\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, harmonic_potential(x))\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$x^2$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a potential $\\phi(x) = x^2$ as shown above.\n",
    "According to statistical mechanics, the probablility to observe a\n",
    "position/configuration $x$ is proportional to the Boltzmann weight\n",
    "\n",
    "$$\n",
    "p(x) \\propto e^{-\\beta\\phi(x)} = e^{-\\frac{x^2}{\\mathrm{k}_\\mathrm{B}T}}\\,,\n",
    "\\quad \\mathrm{with} \\; \\beta^{-1}=\\mathrm{k}_\\mathrm{B}T\n",
    "$$\n",
    "\n",
    "$\\beta$ is called an inverse temperature and has the dimension of an inverse energy.\n",
    "\n",
    "We further define a uniform grid\n",
    "\n",
    "$$x_i = x_0 + ih \\,,\\; i=0,\\dots,n$$\n",
    "\n",
    "and a sequence of indicator functions\n",
    "\n",
    "$$\\chi_i(x) = \\begin{cases} 1, & x_i \\leq x < x_{i+1} \\\\ 0, & \\mathrm{else} \\end{cases}\\,, \\quad i=0,\\dots,n-1.$$\n",
    "\n",
    "Let us use our previous approach to compute a histogram of positions\n",
    "to approximate the stationary distribution $\\pi(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi(x, xmin, xmax):\n",
    "    return np.logical_and(xmin <= x, x < xmax)\n",
    "\n",
    "\n",
    "positions = np.random.uniform(low=-5, high=5, size=100000)\n",
    "edges = np.linspace(-5, 5, 31)\n",
    "centers = (edges[:-1] + edges[1:]) / 2\n",
    "\n",
    "histogram = [np.sum(chi(positions, x, y)) / positions.size\n",
    "             for x, y in zip(edges[:-1], edges[1:])]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(centers, [h for h in histogram], (edges[1] - edges[0]) * 0.9)\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$\\frac{1}{N}\\sum_{n=1}^N \\chi_i(x_n)$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not look right!\n",
    "The naive averaging yields an approximately constant distribution\n",
    "which is not compatible with the expected Boltzmann distribution.\n",
    "\n",
    "The reason is simply that the naive average does not compute a **weighted** expectation:\n",
    "\n",
    "$$\\frac{1}{N}\\sum_{n=1}^N \\chi_i(x_n) \\neq \\mathbb{E}_p \\left[\\chi_i \\right]$$\n",
    "\n",
    "Instead, we need to compute \n",
    "\n",
    "$$\\sum_{n=1}^N \\chi_i(x_n) p(x_n)\\,, \\quad \\mathrm{with} \\; \\sum_{n=1}^N p(x_n)=1:$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs(iterable):\n",
    "    for x, y in zip(iterable[:-1], iterable[1:]):\n",
    "        yield x, y\n",
    "\n",
    "\n",
    "weights = np.exp(-harmonic_potential(positions) * 1.0)\n",
    "weights /= weights.sum()\n",
    "\n",
    "histogram2 = [np.sum(weights[chi(positions, x, y)])\n",
    "              for x, y in pairs(edges)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(\n",
    "    centers,\n",
    "    [h for h in histogram],\n",
    "    (edges[1] - edges[0]) * 0.9,\n",
    "    label=r'$\\frac{1}{N}\\sum_{n=1}^N \\chi_i(x_n)$')\n",
    "ax.bar(\n",
    "    centers,\n",
    "    [h for h in histogram2],\n",
    "    (edges[1] - edges[0]) * 0.8,\n",
    "    label=r'$\\sum_{n=1}^N \\chi_i(x_n)p(x_n)$')\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this correction, we get the expected distribution, but we are still wasting computational effort.\n",
    "\n",
    "A better strategy is to exploit that we can directly sample from the Boltzmann distribution in our case of a harmonic potential. We just have to replace the way we draw random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.random.normal(size=100000)\n",
    "edges = np.linspace(-5, 5, 31)\n",
    "centers = (edges[:-1] + edges[1:]) / 2\n",
    "\n",
    "histogram = [np.sum(chi(positions, x, y)) / positions.size\n",
    "             for x, y in zip(edges[:-1], edges[1:])]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(centers, [h for h in histogram], (edges[1] - edges[0]) * 0.9)\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$\\frac{1}{N}\\sum_{n=1}^N \\chi_i(x_n)$, $x_n\\sim\\mathcal{N}(0, 1)$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can sample directly from $p$, we can compute expectations without reweighting.\n",
    "\n",
    "In most cases, however, we cannot **directly** sample from $p$ and we have to resort to more complicated procedures,\n",
    "e.g., sampling a Markov chain of positions/configurations using the Metropolis scheme\n",
    "where we accept a transition from $x$ to $y$ with the conditional acceptance probablility\n",
    "\n",
    "$$\\mathbb{A}(y|x) = \\min\\left\\{1, \\exp\\left(\\beta(\\phi(x) - \\phi(y))\\right)\\right\\}.$$\n",
    "\n",
    "### Exercise:\n",
    "\n",
    "Complete the following function to implement the Metropolis sampling algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmc(potential, size, x_init=0.0, beta=1.0, step=0.5):\n",
    "    from random import uniform\n",
    "    x, u = np.zeros(size), np.zeros(size)\n",
    "    x[0] = x_init\n",
    "    u[0] = potential(x_init)\n",
    "    for i in range(1, size):\n",
    "        pass\n",
    "    return x, u\n",
    "\n",
    "\n",
    "positions, energies = mmc(harmonic_potential, 10000)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(positions[:400], label=r'positions')\n",
    "ax.plot(energies[:400], label=r'energies')\n",
    "ax.set_xlabel(r'$t$ / steps')\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.linspace(positions.min(), positions.max(), 31)\n",
    "centers = (edges[:-1] + edges[1:]) / 2\n",
    "\n",
    "histogram = [np.sum(chi(positions, x, y)) / positions.size\n",
    "             for x, y in zip(edges[:-1], edges[1:])]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(centers, [h for h in histogram], (edges[1] - edges[0]) * 0.9)\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$\\frac{1}{N}\\sum_{n=1}^N \\chi_i(x_n)$, $x_n\\sim e^{-\\beta\\phi(x_n)}$')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
